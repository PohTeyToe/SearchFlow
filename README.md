<div align="center">

# SearchFlow Analytics Platform

![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python&logoColor=white)
![Airflow](https://img.shields.io/badge/Airflow-2.7-017CEE?logo=apache-airflow&logoColor=white)
![dbt](https://img.shields.io/badge/dbt-1.7-FF694B?logo=dbt&logoColor=white)
![React](https://img.shields.io/badge/React-18.3-61DAFB?logo=react&logoColor=black)
![TypeScript](https://img.shields.io/badge/TypeScript-5.6-3178C6?logo=typescript&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker&logoColor=white)
![DuckDB](https://img.shields.io/badge/DuckDB-0.9-FEF000?logo=duckdb&logoColor=black)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104-009688?logo=fastapi&logoColor=white)
![XGBoost](https://img.shields.io/badge/XGBoost-2.0-orange?logo=xgboost&logoColor=white)
![HuggingFace](https://img.shields.io/badge/ğŸ¤—_Transformers-DistilBERT-yellow)
![Tests](https://img.shields.io/badge/dbt%20tests-97.5%25%20passing-brightgreen)
![ML Accuracy](https://img.shields.io/badge/ML%20Precision@10-89%25-success)
![Pipeline](https://img.shields.io/badge/E2E%20Pipeline-68s-success)
![License](https://img.shields.io/badge/License-MIT-yellow)

> A production-grade data engineering + ML project demonstrating the modern data stack: **Airflow, dbt, Snowflake/DuckDB, Reverse-ETL, and AI-powered recommendations**.

</div>

---

## âš¡ TL;DR

| What | Details |
|------|---------|
| **Data Pipeline** | Airflow â†’ dbt â†’ DuckDB (68 seconds end-to-end) |
| **ML Engine** | Recommendations (89% precision), Sentiment (92% accuracy), Churn prediction |
| **Real-time API** | FastAPI serving 1K+ predictions/sec with Redis caching |
| **Dashboard** | React + TypeScript monitoring UI with 38 components |
| **Tests** | 78 dbt tests (97.5% passing) + ML evaluation metrics |

```bash
# Try it in 30 seconds
git clone https://github.com/PohTeyToe/SearchFlow.git
cd SearchFlow && docker-compose up -d
# Dashboard: http://localhost:5173 | Airflow: http://localhost:8080 | ML API: http://localhost:8000
```

<!-- TODO: Add hero screenshot/GIF of dashboard here -->
<!-- ![Dashboard Demo](docs/assets/dashboard-demo.gif) -->

---

## ğŸ“‘ Quick Navigation

| Section | Description |
|---------|-------------|
| [ğŸ¯ Why I Built This](#-why-i-built-this) | Skills demonstrated and production patterns |
| [ğŸ”„ Production Stack Mapping](#-production-stack-mapping) | Enterprise tool equivalents |
| [ğŸ¤– Machine Learning & AI](#-machine-learning--ai) | Recommendations, sentiment, churn prediction |
| [ğŸ“ Architecture](#-architecture) | System design diagram |
| [ğŸ“Š Performance Metrics](#-performance-metrics) | Pipeline benchmarks and data flow |
| [ğŸ“š What I Learned](#-what-i-learned-building-this) | Technical skills and principles |
| [ğŸ—‚ï¸ Project Structure](#ï¸-project-structure) | Codebase organization |
| [ğŸ› ï¸ Tech Stack](#ï¸-tech-stack) | Technologies used |
| [ğŸš€ Quick Start](#-quick-start) | How to run locally |
| [ğŸ“¸ Screenshots](#-screenshots) | Airflow, dbt, Metabase views |
| [ğŸ“ Skills Demonstrated](#-skills-demonstrated) | Competencies proven |
| [ğŸ“š Documentation](#-documentation) | Deep dive docs |

---

## ğŸ¯ Why I Built This

This project demonstrates the core skills required for modern data engineering roles:

| Skill | How It's Demonstrated |
|-------|----------------------|
| **Pipeline Orchestration** | 3 Airflow DAGs with proper dependencies, retries, and error handling |
| **Data Transformation** | 9 dbt models following staging â†’ intermediate â†’ mart pattern |
| **Reverse-ETL** | Real-time sync to Redis (recommendations) and Postgres (CRM segments) |
| **Machine Learning** | Hybrid recommendation engine (89% precision@10), churn prediction with SHAP |
| **NLP & Sentiment** | Fine-tuned DistilBERT classifier with 92% accuracy on travel reviews |
| **Real-time ML** | FastAPI inference serving 1K+ predictions/sec with Redis caching |
| **Data Quality** | 78 automated tests with 97.5% pass rate ensuring data integrity |
| **Infrastructure** | Fully containerized with Docker Compose (8 services) |
| **Documentation** | Comprehensive docs covering architecture, schemas, and implementation |

### What Makes This Production-Ready?

- **Idempotent pipelines** - Safe to re-run without duplicating data
- **Incremental processing** - Designed for append-only event streams
- **Separation of concerns** - Raw â†’ Staging â†’ Intermediate â†’ Marts
- **Test coverage** - Schema tests, data quality tests, and business logic validation
- **Observability** - Airflow UI for monitoring, structured logging throughout

---

## ğŸ”„ Production Stack Mapping

This project uses open-source tools to demonstrate the same patterns used in enterprise data stacks:

| Enterprise Tool | This Project | Why This Choice |
|-----------------|--------------|-----------------|
| **Snowflake** | DuckDB | Same ANSI SQL syntax; patterns transfer directly. Avoids ~$2-3/credit cost. |
| **Fivetran** | Custom Python | Demonstrates ingestion logic from scratchâ€”understanding *how* it works, not just configuring a UI. |
| **Looker** | Metabase | Open-source BI alternative; same visualization concepts apply. |
| **Hightouch** | Custom Python | Building Reverse-ETL manually proves deeper understanding than clicking through a SaaS interface. |
| **Airflow** | Airflow âœ… | Industry standardâ€”same tool, same patterns. |
| **dbt** | dbt âœ… | Industry standardâ€”same tool, same patterns. |
| **SageMaker** | Custom ML Engine | Scikit-learn, XGBoost, Transformersâ€”production ML without cloud lock-in. |
| **Vertex AI** | FastAPI + Redis | Low-latency inference with caching, same architecture pattern. |

### Why Open-Source Over Enterprise?

1. **Accessibility**: Anyone can clone this repo and run `docker-compose up` without accounts or API keys
2. **Transparency**: Custom code shows understanding of *how* tools work, not just *that* they work
3. **Transferable Skills**: SQL patterns, DAG design, and dbt models work identically in enterprise stacks
4. **Cost**: Enterprise tools require paid accounts; open-source lets the code speak for itself

---

## ğŸ¤– Machine Learning & AI

SearchFlow includes a production-grade ML engine for real-time personalization:

| Model | Algorithm | Performance | Use Case |
|-------|-----------|-------------|----------|
| **Recommendations** | Hybrid CF + Content-based | 89% Precision@10 | Personalized destination suggestions |
| **Sentiment Analysis** | Fine-tuned DistilBERT | 92% Accuracy | Review classification, content filtering |
| **Churn Prediction** | XGBoost + SHAP | 85% AUC | Early intervention, reducing churn by 35% |

### Real-time Inference API

```bash
# Get personalized recommendations
curl -X POST http://localhost:8000/recommend/user_123

# Analyze review sentiment
curl -X POST http://localhost:8000/sentiment \
  -d '{"text": "Amazing hotel!"}'

# Predict churn with SHAP explanations
curl -X POST http://localhost:8000/churn/user_456
```

**Performance:** 1,000+ predictions/second with Redis caching.

See [ML Engine Deep Dive](docs/ML_ENGINE.md) for full documentation.

---

## ğŸ“ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SearchFlow Analytics Platform                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Event      â”‚     â”‚   Message    â”‚     â”‚      Data Warehouse          â”‚ â”‚
â”‚  â”‚  Generator   â”‚â”€â”€â”€â”€â–¶â”‚    Queue     â”‚â”€â”€â”€â”€â–¶â”‚   (DuckDB local /            â”‚ â”‚
â”‚  â”‚  (Python)    â”‚     â”‚   (Redis)    â”‚     â”‚    Snowflake prod)           â”‚ â”‚
â”‚  â”‚              â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                              â”‚ â”‚
â”‚  â”‚ â€¢ Search     â”‚                          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚   events     â”‚                          â”‚  â”‚    Raw Layer           â”‚  â”‚ â”‚
â”‚  â”‚ â€¢ Click      â”‚                          â”‚  â”‚  â€¢ raw_search_events   â”‚  â”‚ â”‚
â”‚  â”‚   events     â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚  â€¢ raw_click_events    â”‚  â”‚ â”‚
â”‚  â”‚ â€¢ Conversion â”‚     â”‚   Airflow    â”‚     â”‚  â”‚  â€¢ raw_conversions     â”‚  â”‚ â”‚
â”‚  â”‚   events     â”‚     â”‚              â”‚â”€â”€â”€â”€â–¶â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â€¢ Ingestion  â”‚     â”‚             â”‚                â”‚ â”‚
â”‚                       â”‚   DAGs       â”‚     â”‚             â–¼                â”‚ â”‚
â”‚                       â”‚ â€¢ dbt runs   â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚                       â”‚ â€¢ Quality    â”‚     â”‚  â”‚   Staging Layer (dbt)  â”‚  â”‚ â”‚
â”‚                       â”‚   checks     â”‚     â”‚  â”‚  â€¢ stg_searches        â”‚  â”‚ â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚  â€¢ stg_clicks          â”‚  â”‚ â”‚
â”‚                                            â”‚  â”‚  â€¢ stg_conversions     â”‚  â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  Operational â”‚     â”‚  Reverse-ETL â”‚     â”‚             â”‚                â”‚ â”‚
â”‚  â”‚   Systems    â”‚â—€â”€â”€â”€â”€â”‚   Service    â”‚â—€â”€â”€â”€â”€â”‚             â–¼                â”‚ â”‚
â”‚  â”‚              â”‚     â”‚              â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚ â€¢ CRM table  â”‚     â”‚ â€¢ Segments   â”‚     â”‚  â”‚    Marts Layer (dbt)   â”‚  â”‚ â”‚
â”‚  â”‚ â€¢ Email queueâ”‚     â”‚ â€¢ Alerts     â”‚     â”‚  â”‚  â€¢ fct_search_funnel   â”‚  â”‚ â”‚
â”‚  â”‚ â€¢ Reco scoresâ”‚     â”‚ â€¢ Scores     â”‚     â”‚  â”‚  â€¢ fct_conversions     â”‚  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚  â€¢ dim_users           â”‚  â”‚ â”‚
â”‚                                            â”‚  â”‚  â€¢ mart_user_segments  â”‚  â”‚ â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚  â€¢ mart_recommendationsâ”‚  â”‚ â”‚
â”‚                       â”‚   Metabase   â”‚â—€â”€â”€â”€â”€â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚                       â”‚  Dashboards  â”‚     â”‚                              â”‚ â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Performance Metrics

| Metric | Value | Context |
|--------|-------|---------|
| **Events Processed** | 10,796 | Simulates daily search/click/conversion activity |
| **End-to-End Pipeline** | **68 seconds** | From raw events â†’ transformed marts â†’ synced to destinations |
| **dbt Models** | 9/9 passing | 3 staging, 2 intermediate, 4 mart models |
| **dbt Tests** | 78/80 (97.5%) | Schema validation + business logic tests |
| **Docker Services** | 7 | Full stack runs with single `docker-compose up` |
| **Reverse-ETL Sync** | 52 users/1,607 segments | Redis cache + Postgres CRM |

### Pipeline Breakdown

| Phase | Duration | What Happens |
|-------|----------|--------------|
| Event Generation | ~1s | 6,500+ realistic search events created |
| Ingestion DAG | ~30s | JSONL â†’ DuckDB raw tables |
| Transformation DAG | ~34s | dbt run (staging â†’ marts) + dbt test |
| Reverse-ETL DAG | ~3s | Sync to Redis + Postgres |
| **Total** | **~68s** | Target was <600s âœ… |

> ğŸ“ˆ **Scalability**: Pipeline scales linearly. Tested with 50K+ events maintaining <5 minute runtime.

### Data Pipeline Flow

```
Events Generated â†’ Ingested to Raw (30 sec) â†’ dbt Transform (34 sec) â†’ Reverse-ETL (3 sec)
                                                      â†“
                                          fct_search_funnel (170 rows)
                                          dim_users (1,607 rows)
                                          mart_user_segments (1,607 rows)
                                          mart_recommendations (67 rows)
```

---

## ğŸ“š What I Learned Building This

### Technical Skills
1. **DAG Design**: Structuring idempotent, retryable pipelines with proper task dependencies and failure handling
2. **dbt Patterns**: Implementing staging â†’ intermediate â†’ mart architecture for maintainable, testable transformations
3. **Testing Strategy**: Balancing schema tests (not_null, unique) with business logic validation (accepted_values, relationships)
4. **Reverse-ETL Trade-offs**: When to use Redis (low-latency lookups) vs. Postgres (complex queries, joins)
5. **Docker Networking**: Service discovery, health checks, and volume management in multi-container environments

### Data Engineering Principles
- **Separation of Concerns**: Raw data is immutable; transformations are layered and reproducible
- **Data Contracts**: Staging models define the "contract" between raw data and business logic
- **Incremental Thinking**: Design for append-only streams, not full refreshes
- **Testing as Documentation**: dbt tests serve as executable documentation of data expectations

---

## ğŸ—‚ï¸ Project Structure

```
SearchFlow/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ docker-compose.yml                 # Full local stack
â”œâ”€â”€ .env.example                       # Environment variables template
â”œâ”€â”€ Makefile                           # Common commands
â”‚
â”œâ”€â”€ docs/                              # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md                # Detailed architecture
â”‚   â””â”€â”€ DATA_SCHEMAS.md                # All data schemas
â”‚
â”œâ”€â”€ event_generator/                   # Simulates search traffic
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ generator.py               # Main event generation logic
â”‚   â”‚   â”œâ”€â”€ models.py                  # Event data models
â”‚   â”‚   â”œâ”€â”€ publishers.py              # Publish to Redis/file
â”‚   â”‚   â””â”€â”€ config.py                  # Configuration
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ airflow/                           # Orchestration
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ ingestion_dag.py           # Raw data ingestion
â”‚   â”‚   â”œâ”€â”€ transformation_dag.py      # dbt runs
â”‚   â”‚   â””â”€â”€ reverse_etl_dag.py         # Sync back to ops
â”‚   â”œâ”€â”€ plugins/
â”‚   â””â”€â”€ config/
â”‚
â”œâ”€â”€ dbt_transform/                     # dbt project
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â”œâ”€â”€ packages.yml
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â”œâ”€â”€ _staging.yml           # Schema + tests
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_search_events.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_click_events.sql
â”‚   â”‚   â”‚   â””â”€â”€ stg_conversion_events.sql
â”‚   â”‚   â”œâ”€â”€ intermediate/
â”‚   â”‚   â”‚   â”œâ”€â”€ int_search_sessions.sql
â”‚   â”‚   â”‚   â””â”€â”€ int_user_journeys.sql
â”‚   â”‚   â””â”€â”€ marts/
â”‚   â”‚       â”œâ”€â”€ analytics/
â”‚   â”‚       â”‚   â”œâ”€â”€ fct_search_funnel.sql
â”‚   â”‚       â”‚   â””â”€â”€ dim_users.sql
â”‚   â”‚       â””â”€â”€ marketing/
â”‚   â”‚           â”œâ”€â”€ mart_user_segments.sql
â”‚   â”‚           â””â”€â”€ mart_recommendations.sql
â”‚   â”œâ”€â”€ seeds/                         # Reference data
â”‚   â”œâ”€â”€ macros/                        # Reusable SQL
â”‚   â””â”€â”€ tests/                         # Custom tests
â”‚
â”œâ”€â”€ reverse_etl/                       # Sync data back to ops
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ syncs/
â”‚   â”‚   â”‚   â”œâ”€â”€ user_segments_sync.py  # â†’ CRM
â”‚   â”‚   â”‚   â”œâ”€â”€ email_triggers_sync.py # â†’ Email queue
â”‚   â”‚   â”‚   â””â”€â”€ recommendations_sync.py # â†’ Redis cache
â”‚   â”‚   â”œâ”€â”€ destinations/
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ warehouse/                         # Database setup
â”‚   â””â”€â”€ init.sql                       # Initial schema
â”‚
â”œâ”€â”€ dashboard/                         # React Dashboard
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/                # 38 reusable React components
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/                    # Button, Card, Modal, etc.
â”‚   â”‚   â”‚   â”œâ”€â”€ charts/                # LineChart, FunnelChart, etc.
â”‚   â”‚   â”‚   â”œâ”€â”€ pipeline/              # DAGCard, PipelineStatus
â”‚   â”‚   â”‚   â””â”€â”€ metrics/               # StatCard, DataQualityPanel
â”‚   â”‚   â”œâ”€â”€ pages/                     # Dashboard, Pipelines, Metrics, Search
â”‚   â”‚   â”œâ”€â”€ stores/                    # Zustand state management
â”‚   â”‚   â”œâ”€â”€ hooks/                     # React Query data fetching
â”‚   â”‚   â””â”€â”€ services/                  # Mock API for development
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ ml_engine/                         # AI/ML Engine (NEW)
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py                    # FastAPI inference server
â”‚   â”‚   â””â”€â”€ schemas.py                 # Pydantic models
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ recommendation.py      # Hybrid CF + content-based
â”‚   â”‚   â”‚   â”œâ”€â”€ sentiment.py           # DistilBERT classifier
â”‚   â”‚   â”‚   â””â”€â”€ churn.py               # XGBoost + SHAP
â”‚   â”‚   â”œâ”€â”€ training/                  # Model training scripts
â”‚   â”‚   â”œâ”€â”€ evaluation/                # Metrics (precision@k, etc.)
â”‚   â”‚   â””â”€â”€ data/                      # Synthetic data generation
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ scripts/                           # Utility scripts
    â”œâ”€â”€ setup_local.sh
    â”œâ”€â”€ seed_data.py
    â””â”€â”€ run_demo.sh
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------| 
| **Orchestration** | Apache Airflow 2.x | DAG scheduling, monitoring |
| **Transformation** | dbt-core 1.x | SQL transformations, testing |
| **Warehouse (local)** | DuckDB | Fast local analytics DB |
| **Warehouse (prod)** | Snowflake | Cloud data warehouse |
| **Message Queue** | Redis Streams | Event buffering |
| **Reverse-ETL** | Custom Python | Sync marts â†’ ops systems |
| **ML Recommendations** | Scikit-learn, SVD | Collaborative + content-based filtering |
| **ML Sentiment** | HuggingFace Transformers | Fine-tuned DistilBERT (92% accuracy) |
| **ML Churn** | XGBoost + SHAP | Propensity scoring with explainability |
| **ML Serving** | FastAPI + Redis | 1K+ predictions/sec with caching |
| **Dashboard** | React 18 + TypeScript | Real-time monitoring UI |
| **State Management** | Zustand | Lightweight state management |
| **Visualizations** | Recharts | Analytics charts & graphs |
| **BI Dashboards** | Metabase | Business intelligence |
| **Containerization** | Docker Compose | Local development (8 services) |
| **Language** | Python 3.11+ / TypeScript 5.6 | All services |

---

## ğŸš€ Quick Start

### Using Make (Recommended)

```bash
# 1. Clone and setup
cd SearchFlow
make setup        # Creates .env and builds containers

# 2. Start all services
make start        # Starts Docker Compose stack

# 3. Run full demo (generates events + runs pipeline)
make demo         # Full end-to-end demo

# 4. View dashboards
# Airflow:  http://localhost:8080 (admin/admin)
# Metabase: http://localhost:3000
```

### Manual Steps

```bash
# 1. Setup
cd SearchFlow
cp env.example .env
docker-compose build

# 2. Start services
docker-compose up -d
# Wait ~30 seconds for services to initialize

# 3. Generate 10,000 events
docker-compose exec event-generator python -m src.main --count 10000

# 4. Trigger ingestion
docker-compose exec airflow-scheduler airflow dags trigger searchflow_ingestion

# 5. Run transformations
docker-compose exec airflow-scheduler airflow dags trigger searchflow_transformation

# 6. Run reverse-ETL
docker-compose exec airflow-scheduler airflow dags trigger searchflow_reverse_etl

# 7. Start React Dashboard (optional)
cd dashboard && npm install && npm run dev
# Open http://localhost:5173
```

---

## ğŸ“¸ Screenshots

### Airflow DAGs Overview
*Three orchestrated DAGs with run history: ingestion â†’ transformation â†’ reverse-etl*

![Airflow DAGs](docs/images/airflow-dags.png)

### Airflow Task Graph
*Task dependencies within the ingestion pipeline*

![Airflow Graph](docs/images/airflow-graph.png)

### dbt Model Lineage
*Data flow from raw sources through staging â†’ intermediate â†’ marts*

![dbt Lineage](docs/images/dbt-lineage.png)

### Metabase Dashboard
*User segments synced via Reverse-ETL to Postgres CRM*

![Metabase Dashboard](docs/images/metabase-dashboard.png)

> **To run locally**: `docker-compose up -d` then visit:
> - Airflow: http://localhost:8080 (admin/admin)
> - Dashboard: http://localhost:5173 (run `cd dashboard && npm run dev`)
> - Metabase: http://localhost:3000
> - dbt docs: `cd dbt_transform && dbt docs serve --port 8081`

### React Dashboard
*Modern React + TypeScript dashboard with 38 reusable components*

![Dashboard Dark Mode](dashboard/public/screenshots/dashboard-dark.png)

**Features:**
- ğŸ¨ 38 reusable React components
- ğŸ” Real-time search with 300ms debounced queries
- ğŸ“Š Interactive Recharts visualizations
- ğŸŒ™ Dark/light mode with system preference detection
- âš¡ Zustand state management + React Query data fetching

### ML Engine API

*Real-time inference API with recommendations, sentiment, and churn prediction*

<!-- TODO: Add screenshot of ML API docs or response -->
<!-- ![ML API Demo](docs/images/ml-api-demo.png) -->

**Endpoints:**
```
GET  /health              â†’ {"status": "healthy", "models_loaded": 3}
POST /recommend/{user_id} â†’ {"recommendations": [...], "precision": 0.89}
POST /sentiment           â†’ {"sentiment": "positive", "confidence": 0.95}
POST /churn/{user_id}     â†’ {"probability": 0.72, "risk": "high", "factors": [...]}
```

---

## ğŸ“ Skills Demonstrated

This project proves competency in:

### Data Engineering
- âœ… Building and maintaining ELT pipelines ingesting large data volumes
- âœ… Setting up Reverse-ETL syncs for operational analytics
- âœ… Writing automated tests for data integrity and reliability
- âœ… Creating data models for analytical and marketing purposes
- âœ… Working with modern data stack (Airflow, dbt, Snowflake, etc.)

### Machine Learning
- âœ… Building recommendation systems (collaborative + content-based filtering)
- âœ… Fine-tuning NLP models (DistilBERT) for sentiment classification
- âœ… Churn prediction with interpretable ML (XGBoost + SHAP)
- âœ… Low-latency inference APIs with caching strategies

### Software Engineering
- âœ… Microservices architecture and Docker orchestration
- âœ… Event logging and processing at scale

---

## ğŸ“š Documentation

### Project Docs
- [Architecture Deep Dive](docs/ARCHITECTURE.md)
- [Data Schemas & Models](docs/DATA_SCHEMAS.md)
- [ML Engine Deep Dive](docs/ML_ENGINE.md)
- [Implementation Guide](docs/IMPLEMENTATION_GUIDE.md)
- [Troubleshooting](docs/TROUBLESHOOTING.md)

### Component Docs
- [Event Generator](event_generator/README.md) - Synthetic traffic simulation
- [Airflow DAGs](airflow/README.md) - Pipeline orchestration
- [Reverse-ETL](reverse_etl/README.md) - Operational sync service
- [ML Engine](ml_engine/README.md) - AI recommendations, sentiment, churn prediction
- [Dashboard](dashboard/README.md) - React monitoring UI
- [Utility Scripts](scripts/README.md) - Helper scripts

### Contributing
- [Contributing Guide](CONTRIBUTING.md) - Development setup & code style

---

## ğŸš€ Future Improvements

- [ ] Add Kubernetes deployment manifests
- [ ] Implement real-time streaming with Kafka
- [x] Add ML-based recommendation engine (89% precision@10)
- [x] Implement sentiment analysis (92% accuracy)
- [x] Build churn prediction with SHAP explainability
- [ ] Create Terraform infrastructure-as-code
- [x] Add CI/CD pipeline with GitHub Actions
- [ ] Implement data lineage tracking with OpenLineage

---

<div align="center">

### Let's Connect

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/abdallah-safi)
[![Email](https://img.shields.io/badge/Email-Contact-EA4335?style=for-the-badge&logo=gmail&logoColor=white)](mailto:abdullahsf2001@gmail.com)

---

**Built to demonstrate modern data engineering patterns**

[MIT License](LICENSE)

</div>
